% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train.R
\name{train}
\alias{train}
\title{Train Supervised Learning Models}
\usage{
train(
  x,
  dat_validation = NULL,
  dat_test = NULL,
  weights = NULL,
  algorithm = NULL,
  preprocessor_config = NULL,
  hyperparameters = NULL,
  tuner_config = NULL,
  outer_resampling_config = NULL,
  execution_config = setup_ExecutionConfig(),
  question = NULL,
  outdir = NULL,
  verbosity = 1L,
  ...
)
}
\arguments{
\item{x}{tabular data, i.e. data.frame, data.table, or tbl_df (tibble): Training set data.}

\item{dat_validation}{tabular data: Validation set data.}

\item{dat_test}{tabular data: Test set data.}

\item{weights}{Optional vector of case weights.}

\item{algorithm}{Character: Algorithm to use. Can be left NULL, if \code{hyperparameters} is defined.}

\item{preprocessor_config}{PreprocessorConfig object or NULL: Setup using \link{setup_Preprocessor}.}

\item{hyperparameters}{\code{Hyperparameters} object: Setup using one of \verb{setup_*} functions.}

\item{tuner_config}{TunerConfig object: Setup using \link{setup_GridSearch}.}

\item{outer_resampling_config}{ResamplerConfig object or NULL: Setup using \link{setup_Resampler}.
This defines the outer resampling method, i.e. the splitting into training and test sets for the
purpose of assessing model performance. If NULL, no outer resampling is performed, in which case
you might want to use a \code{dat_test} dataset to assess model performance on a single test set.}

\item{execution_config}{\code{ExecutionConfig} object: Setup using \link{setup_ExecutionConfig}. This
allows you to set backend ("future", "mirai", or "none"), number of workers, and future plan if
using \code{backend = "future"}.}

\item{question}{Optional character string defining the question that the model is trying to
answer.}

\item{outdir}{Character, optional: String defining the output directory.}

\item{verbosity}{Integer: Verbosity level.}

\item{...}{Not used.}
}
\value{
Object of class \code{Regression(Supervised)}, \code{RegressionRes(SupervisedRes)},
\code{Classification(Supervised)}, or \code{ClassificationRes(SupervisedRes)}.
}
\description{
Preprocess, tune, train, and test supervised learning models in a single call
using nested resampling.
}
\details{
\strong{Online book & documentation}

See \href{https://rdocs.rtemis.org/train}{rdocs.rtemis.org/train} for detailed documentation.

\strong{Preprocessing}

There are many different stages at which preprocessing could be applied, when running a
supervised learning pipeline with nested resampling. Some operations are best done before
passing data to \code{train()}:
\itemize{
\item Duplicate rows should be removed before resampling, so that duplicates don't end up in
different resamples, e.g. one in training and one in test.
\item Constant columns should be removed before resampling. A column may appear constant in a small
resample, even if it is not constant in the full dataset. Removing it inconsistently will
throw an error during prediction.
\item All data-dependent preprocessing steps need to be performed on training data only and applied
on validation and test data, e.g. scaling, centering, imputation.
}

User-defined preprocessing through \code{preprocessor_config} is applied on training set data,
the learned parameters are stored in the returned Supervised or SupervisedRes object, and the
preprocessing is applied on validation and test data.

\strong{Binary Classification}

For binary classification, the outcome should be a factor where the 2nd level
corresponds to the positive class.

\strong{Resampling}

Note that you should not use an outer resampling method with
replacement if you will also be using an inner resampling (for tuning).
The duplicated cases from the outer resampling may appear both in the
training and test sets of the inner resamples, leading to underestimated
test error.

\strong{Reproducibility}

If using \emph{\strong{outer resampling}}, you can set a seed when defining \code{outer_resampling_config}, e.g.

\if{html}{\out{<div class="sourceCode r">}}\preformatted{outer_resampling_config = setup_Resampler(n_resamples = 10L, type = "KFold", seed = 2026L)
}\if{html}{\out{</div>}}

If using \emph{\strong{tuning with inner resampling}}, you can set a seed when defining \code{tuner_config},
e.g.

\if{html}{\out{<div class="sourceCode r">}}\preformatted{tuner_config = setup_GridSearch(
  resampler_config = setup_Resampler(n_resamples = 5L, type = "KFold", seed = 2027L)
)
}\if{html}{\out{</div>}}

\strong{Parallelization}

There are three levels of parallelization that may be used during training:
\enumerate{
\item Algorithm training (e.g. a parallelized learner like LightGBM)
\item Tuning (inner resampling, where multiple resamples can be processed in parallel)
\item Outer resampling (where multiple outer resamples can be processed in parallel)
}

The \code{train()} function will automatically manage parallelization depending
on:
\itemize{
\item The number of workers specified by the user using \code{n_workers}
\item Whether the training algorithm supports parallelization itself
\item Whether hyperparameter tuning is needed
}
}
\examples{
\donttest{
iris_c_lightRF <- train(
   iris,
   algorithm = "LightRF",
   outer_resampling_config = setup_Resampler(),
)
}
}
\author{
EDG
}
