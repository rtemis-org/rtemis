% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/00_S7_init.R
\name{train}
\alias{train}
\title{Train Supervised Learning Models}
\usage{
train(x, ...)
}
\arguments{
\item{x}{Tabular data OR \code{SuperConfig} object. See below for usage and arguments for each method.}

\item{...}{Not used.}
}
\value{
Object of class \code{Regression}, \code{RegressionRes}, \code{Classification}, or \code{ClassificationRes}
}
\description{
Preprocess, tune, train, and test supervised learning models with a single call
using nested resampling.
}
\details{
See \href{https://rdocs.rtemis.org/train}{rdocs.rtemis.org/train} for detailed documentation.
}
\section{S7 method for tabular input (\code{data.frame}, \code{data.table}, \code{tbl_df})}{


\strong{Usage}

\if{html}{\out{<div class="sourceCode R">}}\preformatted{train(x, dat_validation = NULL, dat_test = NULL, weights = NULL, algorithm = NULL,
  preprocessor_config = NULL, hyperparameters = NULL, tuner_config = NULL,
  outer_resampling_config = NULL, execution_config = setup_ExecutionConfig(),
  question = NULL, outdir = NULL, verbosity = 1L
 )
}\if{html}{\out{</div>}}

\strong{Arguments}
\itemize{
\item \code{dat_validation}: data.frame or similar. Optional validation set.
\item \code{dat_test}: data.frame or similar. Optional test set.
\item \code{weights}: Numeric vector or NULL. Optional case weights.
\item \code{algorithm}: Character. Algorithm to use (ignored if \code{hyperparameters} is set).
\item \code{preprocessor_config}: \code{PreprocessorConfig} object or NULL. Setup using \code{setup_Preprocessor}.
\item \code{hyperparameters}: \code{Hyperparameters} object. Setup using one of the \verb{setup_*} functions.
\item \code{tuner_config}: \code{TunerConfig} object or NULL. Setup using \code{setup_GridSearch}.
\item \code{outer_resampling_config}: \code{ResamplerConfig} object or NULL. Setup using \code{setup_Resampler}.
\item \code{execution_config}: \code{ExecutionConfig} object. Setup using \code{setup_ExecutionConfig}.
This controls \code{backend}, \code{future_plan}, and \code{n_workers}.
\item \code{question}: Character or NULL. Optional question the model is trying to answer.
\item \code{outdir}: Character or NULL. Output directory.
\item \code{verbosity}: Integer. Verbosity level.
}
}

\section{S7 method for \code{SuperConfig} input}{


\strong{Usage}

\if{html}{\out{<div class="sourceCode R">}}\preformatted{train(x)
}\if{html}{\out{</div>}}

\strong{Arguments}
\itemize{
\item \code{x}: \code{SuperConfig} object.
}
}

\section{Binary Classification}{


Important: For binary classification, the outcome should be a factor where the 2nd level
corresponds to the positive class.
}

\section{Resampling}{


Note on resampling: You should never use an outer resampling method with
replacement if you will also be using an inner resampling (for tuning).
The duplicated cases from the outer resampling may appear both in the
training and test sets of the inner resamples, leading to underestimated
test error.
}

\section{Parallelization}{


There are three levels of parallelization that may be used during training:
\enumerate{
\item Algorithm training (e.g. a parallelized learner like LightGBM)
\item Tuning (inner resampling, where multiple resamples can be processed in parallel)
\item Outer resampling (where multiple outer resamples can be processed in parallel)
}

The \code{train()} function and its sub-functions will automatically manage parallelization depending
on:
\itemize{
\item The number of workers specified by the user via \code{setup_ExecutionConfig}
\item Whether the training algorithm supports parallelization itself
\item Whether hyperparameter tuning is needed
}
}

\examples{
\donttest{
iris_c_lightRF <- train(
   iris,
   algorithm = "LightRF",
   outer_resampling_config = setup_Resampler(),
)
}
}
\author{
EDG
}
